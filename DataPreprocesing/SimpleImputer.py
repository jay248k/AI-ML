# Hours	Marks
# 2	40
# 3	‚ùå
# 4	55

# One mark is missing.

# Machine learning models cannot handle empty values.

# So we must fill them.

# That process is called Imputation.
import pandas as pd
from sklearn.impute import SimpleImputer

data = {
    "Hours": [2, 3, None, 5, 6],
    "Marks": [40, None, 50, 60, 65]
}

df = pd.DataFrame(data)

print("Original Data:")
print(df)

imputer = SimpleImputer(strategy="mean")

df_filled = imputer.fit_transform(df)

print("After Imputation:")
print(df_filled)

# 1Ô∏è‚É£ VERY EASY EXPLANATION

# Imagine student data:

# +-------+-------+
# | Hours | Marks |
# +-------+-------+
# | 2     | 40    |
# | 3     | ‚ùå    |
# | 4     | 55    |
# +-------+-------+

# One mark is missing.

# Machine learning models cannot handle empty values.

# So we must fill them.

# That process is called Imputation.

# SimpleImputer helps us fill missing values automatically.

# üü° 2Ô∏è‚É£ WHY MISSING VALUES ARE PROBLEM?

# If dataset contains:

# None

# NaN

# Blank values

# Model will throw error.

# Example error:

# ValueError: Input contains NaN

# So we must clean data before training.

# 4Ô∏è‚É£ DIFFERENT STRATEGIES

# SimpleImputer has 4 main strategies:

# ‚úÖ 1. Mean (For Numeric Data)

# Replace missing with average value.

# Example:

# Marks = [40, 50, 60]

# Mean = 50

# Missing ‚Üí 50

# Used for:

# Continuous numerical features

# ‚úÖ 2. Median

# Replace missing with middle value.

# Better when:

# Data has outliers

# Example:

# [10, 15, 20, 1000]

# Mean = 261 ‚ùå (affected by 1000)
# Median = 17.5 ‚úÖ (better)

# ‚úÖ 3. Most Frequent

# Used for categorical data.

# Example:

# City:
# Mumbai
# Delhi
# Mumbai
# None

# Most frequent = Mumbai
# Missing ‚Üí Mumbai

# ‚úÖ 4. Constant

# Fill with custom value.

# SimpleImputer(strategy="constant", fill_value=0)

# 5Ô∏è‚É£ CORRECT WAY (Very Important ‚ö†)

# Always split first.

# Then:

# imputer = SimpleImputer(strategy="mean")

# X_train = imputer.fit_transform(X_train)
# X_test = imputer.transform(X_test)

# Never fit on test data.

# Why?

# Because it causes data leakage.

# üü§ 6Ô∏è‚É£ INTERVIEW QUESTIONS

# Q1: Why is imputation necessary?
# Answer:
# Because ML models cannot handle missing values directly.

# Q2: Mean vs Median?
# Answer:
# Use median when outliers exist.

# Q3: What is data leakage?
# Answer:
# Using test data information during training.

# Q4: Can we drop missing rows instead?
# Answer:
# Yes, but only if missing data is very small.

# ‚ö´ 7Ô∏è‚É£ ADVANCED UNDERSTANDING

# SimpleImputer assumes:

# Missing values are random.

# If missing values have pattern,
# simple imputation may reduce model accuracy.

# In advanced ML, we use:

# KNN Imputer

# Iterative Imputer

# Model-based imputation

# üü¢ 8Ô∏è‚É£ REAL-WORLD EXAMPLE (Your Project)

# In resume ranking:

# Some users may not fill:

# Expected salary

# Experience years

# CGPA

# You cannot delete their resume.

# So you fill:

# Salary ‚Üí median salary

# Experience ‚Üí 0 (if fresher)

# CGPA ‚Üí mean CGPA

# This keeps model stable.

# üü° 9Ô∏è‚É£ BIG ML PIPELINE VIEW

# Real ML pipeline:

# Handle missing values (SimpleImputer)

# Encode categorical values

# Scale numeric values

# Train model

# Missing value handling is first step.