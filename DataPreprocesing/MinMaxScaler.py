
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

data = {
    "Hours": [1, 2, 3, 4, 5],
    "Marks": [35, 40, 50, 55, 60]
}

df = pd.DataFrame(data)

print("Original Data:")
print(df)

scaler = MinMaxScaler()

scaled_data = scaler.fit_transform(df)

print("Scaled Data:")
print(scaled_data)

# 1Ô∏è‚É£ VERY EASY EXPLANATION

# Imagine marks are:

# 10, 20, 30, 40, 50

# We want to convert them between:

# 0 and 1

# So:

# 10 ‚Üí 0
# 50 ‚Üí 1
# 30 ‚Üí 0.5

# That‚Äôs what MinMaxScaler does.

# It shrinks data into a fixed range.

# Default range = 0 to 1.

# üü° 2Ô∏è‚É£ FORMULA (Important)

# X_scaled = (X - Xmin) / (Xmax - Xmin)

# Where:

# Xmin = smallest value

# Xmax = largest value

# It rescales data proportionally.

# üîé What happens internally?

# For Hours:

# Min = 1
# Max = 5

# For value 3:


# (3‚àí1)/(5‚àí1)=2/4=0.5

# So:

# 1 ‚Üí 0
# 3 ‚Üí 0.5
# 5 ‚Üí 1

# Everything now between 0 and 1.

# üî¥ 4Ô∏è‚É£ WHY WE USE MinMaxScaler?

# When we want:

# Data in fixed range

# Neural networks

# Image processing

# Deep learning

# When algorithm expects 0‚Äì1 input

# Very common in:

# KNN

# SVM

# KMeans

# Neural Networks

# |----------------------|---------------------------|---------------------------|
# | Feature              | StandardScaler            | MinMaxScaler              |
# |----------------------|---------------------------|---------------------------|
# | Range                | Mean = 0, Std = 1         | 0 to 1                    |
# | Negative Values      | Yes                       | No                        |
# | Affected by Outliers | Less                      | More                      |
# | Distribution Shape   | Makes data Gaussian-like  | Preserves original shape  |
# | Used In              | Most ML models            | Deep Learning mostly      |
# | Formula              | (x - mean) / std          | (x - min) / (max - min)   |
# | Best For             | SVM, Logistic Regression, | Neural Networks           |
# |                      | KNN, PCA                  |                           |
# |----------------------|---------------------------|---------------------------|

# Important:

# MinMaxScaler is sensitive to outliers.

# If max value is very large,
# everything else becomes very small.

# üü§ 6Ô∏è‚É£ IMPORTANT INTERVIEW QUESTIONS

# Q1: When should we use MinMaxScaler?
# Answer:
# When we want fixed range data, especially for neural networks.

# Q2: What is problem with MinMaxScaler?
# Answer:
# If new data has value greater than training max, it may go beyond 1.

# Q3: Should scaling be done before or after split?
# Answer:
# After split.

# Correct method:

# scaler = MinMaxScaler()

# X_train = scaler.fit_transform(X_train)
# X_test = scaler.transform(X_test)

# Never do fit on test data.

# üß† 7Ô∏è‚É£ REAL-WORLD EXAMPLE (Resume Ranking)

# Suppose features:

# Experience ‚Üí 0 to 20
# Skills score ‚Üí 0 to 100
# Salary ‚Üí 2L to 20L

# Ranges are different.

# MinMaxScaler makes all between 0‚Äì1.

# Model treats them equally.

# ‚ö´ WHEN NOT TO USE MinMaxScaler?

# Not necessary for:

# DecisionTree

# RandomForest

# XGBoost

# Trees don‚Äôt care about scale.

# üü¢ SIMPLE SUMMARY

# StandardScaler ‚Üí Center around 0
# MinMaxScaler ‚Üí Shrink between 0 and 1

# Both are feature scaling methods.
