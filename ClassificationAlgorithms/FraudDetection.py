import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Example dataset
data = {
    "Amount": [100, 200, 50000, 150, 300000, 250],
    "Fraud":  [0, 0, 1, 0, 1, 0]
}

df = pd.DataFrame(data)

X = df[["Amount"]]
y = df["Fraud"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

model = RandomForestClassifier()
model.fit(X_train, y_train)

predictions = model.predict(X_test)

print(classification_report(y_test, predictions))

# ğŸ’³ Fraud Detection using Machine Learning

# Used in:

# Credit card transactions

# UPI payments

# Online banking

# Insurance claims

# Big companies like Visa, Mastercard, PayPal use advanced ML for this.

# ğŸŸ¢ 1ï¸âƒ£ VERY EASY EXPLANATION

# Imagine:

# A person normally spends â‚¹500â€“â‚¹2000 in Rajkot.

# Suddenly:

# â‚¹2,00,000 transaction from another country.

# System thinks:

# âš  This looks unusual â†’ Maybe Fraud.

# Fraud detection = Detect unusual patterns.

# ğŸŸ¡ 2ï¸âƒ£ WHAT TYPE OF PROBLEM IS THIS?

# It is:

# ğŸ‘‰ Binary Classification

# 0 â†’ Genuine
# 1 â†’ Fraud

# But here is the big challenge:

# Fraud cases are very rare.

# Example:

# 100,000 transactions
# Only 200 fraud

# That means:

# Highly Imbalanced Dataset âš 

# ğŸ”µ 3ï¸âƒ£ COMPLETE ML PIPELINE

# Step 1 â†’ Collect transaction data

# Features may include:

# Transaction amount

# Time

# Location

# Merchant type

# Device ID

# Previous behavior

# Step 2 â†’ Data Cleaning

# Step 3 â†’ Handle Imbalanced Data

# Step 4 â†’ Train Model

# Step 5 â†’ Evaluate carefully

# ğŸŸ£ 4ï¸âƒ£ BIG CHALLENGE: IMBALANCED DATA

# If 99% are genuine:

# Model can predict:

# Always 0

# Accuracy = 99%

# But it is useless âŒ

# So we use:

# âœ” Precision
# âœ” Recall
# âœ” F1-score
# âœ” ROC-AUC

# NOT just accuracy.

# ğŸ”´ 5ï¸âƒ£ IMPORTANT METRICS

# For Fraud Detection:

# Recall is VERY IMPORTANT.

# Why?

# If fraud is missed â†’ Money loss.

# Recall formula:
# Recall = TP / (TP + FN)

# High recall = Detect most fraud cases.

# ğŸŸ¤ 6ï¸âƒ£ BEST ALGORITHMS FOR FRAUD DETECTION

# âœ” Logistic Regression
# âœ” Random Forest
# âœ” Gradient Boosting
# âœ” XGBoost
# âœ” Neural Networks

# Random Forest & XGBoost are very popular.

# 8ï¸âƒ£ HOW TO HANDLE IMBALANCE?

# Very important ğŸ”¥

# Methods:

# 1ï¸âƒ£ Oversampling (SMOTE)
# 2ï¸âƒ£ Undersampling
# 3ï¸âƒ£ Class weights

# Example in sklearn:

# RandomForestClassifier(class_weight="balanced")

# 9ï¸âƒ£ REAL-WORLD FRAUD FEATURES

# In real systems:

# âœ” Time between transactions
# âœ” IP address change
# âœ” Device fingerprint
# âœ” Amount deviation
# âœ” Location mismatch

# Model learns abnormal behavior patterns.

# ğŸ§  10ï¸âƒ£ INTERVIEW QUESTIONS

# Q1: Why is accuracy not good metric in fraud detection?
# Because data is imbalanced.

# Q2: Which metric is more important?
# Recall (to catch fraud).

# Q3: What is imbalanced dataset?
# One class is much larger than other.

# Q4: How to handle imbalance?
# SMOTE, class weights, resampling.

# Q5: Is fraud detection supervised or unsupervised?
# Mostly supervised, but anomaly detection can be unsupervised.

# ğŸŸ£ 11ï¸âƒ£ ADVANCED CONCEPT

# Sometimes fraud is unknown pattern.

# Then we use:

# âœ” Isolation Forest
# âœ” One-Class SVM
# âœ” Autoencoders

# This is called:

# Anomaly Detection.

# ğŸŸ¢ 12ï¸âƒ£ HOW YOU CAN USE THIS IN PROJECT

# Since you're building MERN + ML projects:

# You can build:

# ğŸ’³ Transaction Fraud Detection API

# Frontend â†’ React
# Backend â†’ Node + Express
# ML Model â†’ Python Flask
# Database â†’ MongoDB

# This will look very strong on resume ğŸ”¥

# ğŸ”¥ 13ï¸âƒ£ SUMMARY

# Fraud Detection:

# âœ” Binary classification
# âœ” Highly imbalanced
# âœ” Recall very important
# âœ” RandomForest / XGBoost common
# âœ” Real-world impact is huge