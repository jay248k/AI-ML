import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

# Sample dataset
data = {
    "Message": [
        "Win money now",
        "Hello how are you",
        "Claim your free prize",
        "Meeting tomorrow at office"
    ],
    "Label": [1, 0, 1, 0]  # 1 = Spam, 0 = Not Spam
}

df = pd.DataFrame(data)

X = df["Message"]
y = df["Label"]

# Convert text to numbers
vectorizer = CountVectorizer()
X_vectorized = vectorizer.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_vectorized, y, test_size=0.2, random_state=42
)

model = MultinomialNB()
model.fit(X_train, y_train)

predictions = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, predictions))


# ğŸ“© Spam Detection using Machine Learning

# This is one of the most classic ML projects.

# Very good for resume + interviews.

# ğŸŸ¢ 1ï¸âƒ£ VERY EASY EXPLANATION

# Goal:

# Given an email or message â†’ Predict:

# Spam âŒ
# Not Spam âœ…

# Example:

# "Win money now!!! Click here!!!" â†’ Spam
# "Meeting at 5 PM tomorrow" â†’ Not Spam

# Model learns from words.

# ğŸŸ¡ 2ï¸âƒ£ HOW SPAM DETECTION WORKS (FULL PIPELINE)

# Step 1 â†’ Collect dataset
# Step 2 â†’ Clean text
# Step 3 â†’ Convert text into numbers
# Step 4 â†’ Train classifier
# Step 5 â†’ Predict

# ğŸ”µ 3ï¸âƒ£ TEXT PREPROCESSING

# Before training, we clean text:

# âœ” Lowercase
# âœ” Remove punctuation
# âœ” Remove stopwords (is, the, atâ€¦)
# âœ” Tokenization (split words)

# Example:

# "WIN Money Now!!!"

# Becomes:

# ["win", "money", "now"]

# ğŸŸ£ 4ï¸âƒ£ CONVERT TEXT TO NUMBERS

# ML models cannot understand text.

# So we use:

# ğŸ‘‰ Bag of Words (CountVectorizer)
# ğŸ‘‰ TF-IDF Vectorizer

# Example:

# Messages:

# "win money"

# "hello friend"

# Vocabulary:

# win, money, hello, friend

# Converted to:

# +--------------+-----+-------+-------+--------+
# | Message      | win | money | hello | friend |
# +--------------+-----+-------+-------+--------+
# | win money    | 1   | 1     | 0     | 0      |
# | hello friend | 0   | 0     | 1     | 1      |
# +--------------+-----+-------+-------+--------+

# ğŸŸ¤ 5ï¸âƒ£ BEST ALGORITHMS FOR SPAM DETECTION

# âœ” Naive Bayes (Most popular)
# âœ” Logistic Regression
# âœ” SVM
# âœ” Random Forest

# Most common in interviews:

# ğŸ‘‰ Multinomial Naive Bayes

# 7ï¸âƒ£ WHY NAIVE BAYES IS GOOD FOR SPAM?

# Because:

# âœ” Fast
# âœ” Works well with word frequency
# âœ” Handles high-dimensional data
# âœ” Good for text classification

# âš« 8ï¸âƒ£ EVALUATION METRICS (VERY IMPORTANT)

# In spam detection:

# Accuracy is NOT enough.

# Better metrics:

# Precision
# Recall
# F1 Score

# Why?

# If spam predicted as not spam â†’ dangerous.

# So recall for spam is important.

# ğŸŸ  9ï¸âƒ£ REAL-WORLD APPLICATIONS

# âœ” Gmail spam filter
# âœ” SMS spam detection
# âœ” YouTube comment filtering
# âœ” Fraud detection
# âœ” Resume keyword filtering

# ğŸ§  10ï¸âƒ£ INTERVIEW QUESTIONS

# Q1: Which algorithm is best for spam detection?
# Multinomial Naive Bayes.

# Q2: Why not use Linear Regression?
# Because it is classification problem.

# Q3: What vectorization techniques are used?
# CountVectorizer, TF-IDF.

# Q4: Why is recall important in spam detection?
# Because missing spam is risky.

# Q5: What is TF-IDF?
# Term Frequency - Inverse Document Frequency.

# ğŸŸ£ 11ï¸âƒ£ ADVANCED VERSION

# Modern spam detection may use:

# âœ” Logistic Regression
# âœ” SVM
# âœ” XGBoost
# âœ” Deep Learning (LSTM, BERT)

# But Naive Bayes is still strong baseline.

# ğŸ”¥ 12ï¸âƒ£ PROJECT IDEA FOR YOU

# You can build:

# Spam Detection Web App using:

# Frontend â†’ React
# Backend â†’ Flask / FastAPI
# Model â†’ MultinomialNB
# Database â†’ MongoDB

# That will look strong on resume ğŸ”¥

# ğŸš€ 13ï¸âƒ£ SUMMARY

# Spam Detection = Text Classification

# Pipeline:

# Text â†’ Clean â†’ Vectorize â†’ Train â†’ Predict

# Best beginner algorithm â†’ Naive Bayes